{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from ./data/ to S3 exploration notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import boto3\n",
    "import zipfile\n",
    "import shutil\n",
    "import progressbar\n",
    "\n",
    "# Notebook specific\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Exploring data\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connections\n",
    "region = 'us-east-1'\n",
    "s3_client = boto3.client('s3', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the list of existing buckets\n",
    "response = s3_client.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Existing buckets:\n  arxiv-etl\n  jbma-data-engineering-us-east\n"
    }
   ],
   "source": [
    "# Output the bucket names\n",
    "print('Existing buckets:')\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Bucket exists: True\n"
    }
   ],
   "source": [
    "# Check if bucket already exists\n",
    "bucket_name = 'arxiv-etl'\n",
    "bucket_exists = False\n",
    "for obj in response['Buckets']:\n",
    "    if obj['Name'] == bucket_name:\n",
    "        bucket_exists = True\n",
    "print(f\"Bucket exists: {bucket_exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Bucket arxiv-etl already exists\n"
    }
   ],
   "source": [
    "# Create bucket if it doesn't exist\n",
    "if not bucket_exists:\n",
    "    s3_client.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket {bucket_name} created\")\n",
    "else: \n",
    "    print(f\"Bucket {bucket_name} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to bucket - replace existing files as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Path: authors\nFile: authors-parsed.json\nPath: citations\nFile: internal-citations.json\nPath: classifications\nFile: subject-classifications.csv\nPath: metadata\nFile: arxiv-metadata-oai-snapshot-sample.json\n"
    }
   ],
   "source": [
    "path = '../data/loading/'\n",
    "directory = os.fsencode(path)\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    dir_name = os.fsdecode(folder)\n",
    "    print(\"Path:\", dir_name)\n",
    "    dir = os.fsencode(os.path.join(path, dir_name))\n",
    "    for file in os.listdir(dir):\n",
    "        file_name = os.fsdecode(file)\n",
    "        print(\"File:\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(s3_client, bucket_name, path, folder_name, file_name):\n",
    "    # https://stackoverflow.com/questions/41827963/track-download-progress-of-s3-file-using-boto3-and-callbacks\n",
    "    full_name = os.path.join(path, folder_name, file_name)\n",
    "    s3_path = f'staging/{folder_name}/{file_name}'\n",
    "\n",
    "    statinfo = os.stat(full_name)\n",
    "\n",
    "    up_progress = progressbar.progressbar.ProgressBar(maxval=statinfo.st_size)\n",
    "\n",
    "    up_progress.start()\n",
    "\n",
    "    def upload_progress(chunk):\n",
    "        clear_output(wait = True) # Only for IPython (Notebook)\n",
    "        up_progress.update(up_progress.currval + chunk)\n",
    "\n",
    "    response = s3_client.upload_file(full_name, bucket_name, s3_path, Callback=upload_progress)\n",
    "\n",
    "    up_progress.finish()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: b'metadata'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-055762e4bde3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mfolder_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Path:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: b'metadata'"
     ]
    }
   ],
   "source": [
    "# Sync data/loaded folder to s3\n",
    "# https://dev.to/razcodes/how-to-copy-files-to-s3-using-boto3-41fp\n",
    "\n",
    "path = '../data/loading/'\n",
    "directory = os.fsencode(path)\n",
    "\n",
    "# https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    folder_name = os.fsdecode(folder)\n",
    "    print(\"Path:\", folder_name)\n",
    "    dir = os.fsencode(os.path.join(path, folder_name))\n",
    "    for file in os.listdir(dir):\n",
    "        file_name = os.fsdecode(file)\n",
    "        if file_name.endswith(\".json\") or file_name.endswith(\".csv\"): \n",
    "            print(\"Uploading\", file_name)\n",
    "            #full_name = os.path.join(folder_name, file_name)\n",
    "            #response = s3_client.upload_file(full_name, bucket_name, f'staging/{file_name}')\n",
    "            response = upload_file(s3_client, bucket_name, path, folder_name, file_name)\n",
    "            if response is not None:\n",
    "                print(\"HTTPStatusCode:\", response['ResponseMetadata']['HTTPStatusCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data/loaded folder \n",
    "shutil.rmtree(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit079b8e0c18c84c07a446e24cf94e2db0",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}