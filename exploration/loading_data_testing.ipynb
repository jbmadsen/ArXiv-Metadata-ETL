{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load authors data from S3 into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connections\n",
    "region = 'us-east-1'\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "s3_resource = boto3.resource('s3', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40995251/reading-an-json-file-from-s3-using-python-boto3/47121263#47121263\n",
    "content_object = s3_resource.Object('arxiv-etl', 'staging/authors/authors-parsed.json')\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "# S3_HOOK read_key --> return obj.get()['Body'].read().decode('utf-8')\n",
    "#json_content = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_content[\"0704.0001\"]\n",
    "file_content[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(file_content, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from local disk into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./../data/loading/authors/authors-parsed.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '{\"0704.0001\": [[\"Bal\\\\u00e1zs\", \"C.\", \"\"], [\"Berger\", \"E. L.\", \"\"], [\"Nadolsky\", \"P. M.\", \"\"], [\"Yuan\", \"C. -P.\", \"\"]], \"0704.0002\": [[\"Streinu\", \"Ileana\", \"\"], [\"Theran\", \"Louis\", \"\"]], \"0704.0003\": [[\"Pan\", \"Hongjun\", \"\"]], \"0704.0004\": [[\"Callan\", \"David\", \"\"]], \"0704.0005\": [[\"Abu-Shammala\", \"Wael\", \"\"], [\"Torchinsky\", \"Alberto\", \"\"]], \"0704.0006\": [[\"Pong\", \"Y. H.\", \"\"], [\"Law\", \"C. K.\", \"\"]], \"0704.0007\": [[\"Corichi\", \"Alejandro\", \"\"], [\"Vukasinac\", \"Tatjana\", \"\"], [\"Zapata\", \"Jose A.\", \"\"]], \"0704.0008\": [[\"Swift\", \"Damian C.\", \"\"]], \"0704.0009\": [[\"Harvey\", \"Paul\", \"\"], [\"Merin\", \"Bruno\", \"\"], [\"Huard\", \"Tracy L.\", \"\"], [\"Rebull\", \"Luisa M.\", \"\"], [\"Chapman\", \"Nicholas\", \"\"], [\"Evans\", \"Neal J.\", \"II\"], [\"Myers\", \"Philip C.\", \"\"]], \"0704.0010\": [[\"Ovchinnikov\", \"Sergei\", \"\"]], \"0704.0011\": [[\"Cunningham\", \"Clifton\", \"\"], [\"Dembele\", \"Lassina\", \"\"]], \"0704.0012\": [[\"Choi\", \"Dohoon\", \"\"]], \"0704.0013\": [[\"Choi\", \"Dohoon\", \"\"], [\"Choie\", \"YoungJu\", \"\"]], \"0704.0014\": [[\"Fujii\", \"Koichi\", \"\"]], \"0704.0015\": [[\"Stahn\", \"Christian\", \"\"]], \"0704.0016\": [[\"Chang\", \"Chao-Hsi\", \"\"], [\"Li\", \"Tong\", \"\"], [\"Li\", \"Xue-Qian\", \"\"], [\"Wang\", \"Yu-Ming\", \"\"]], \"0704.0017\": [[\"Mhlahlo\", \"Nceba\", \"\"], [\"Buckley\", \"David H.\", \"\"], [\"Dhillon\", \"Vikram S.\", \"\"], [\"Potter\", \"Steven B.\", \"\"], [\"Warner\", \"Brian\", \"\"], [\"Woudt\", \"Patric A.\", \"\"]], \"0704.0018\": [[\"Gustavsson\", \"Andreas\", \"\"]], \"0704.0019\": [[\"Konno\", \"Norio\", \"\"]], \"0704.0020\": [[\"The BABAR Collaboration\", \"\", \"\"], [\"Aubert\", \"B.\", \"\"]], \"0704.0021\": [[\"Casagrande\", \"Vanessa\", \"\"], [\"Togashi\", \"Yuichi\", \"\"], [\"Mikhailov\", \"Alexander S.\", \"\"]], \"0704.0022\": [[\"Malham\", \"Simon J. A.\", \"\"], [\"Wiese\", \"Anke\", \"\"]], \"0704.0023\": [[\"Loukitcheva\", \"M. A.\", \"\"], [\"Solanki\", \"S. K.\", \"\"], [\"White\", \"S.\", \"\"]], \"0704.0024\": [[\"Serga\", \"A. A.\", \"\"], [\"Kostylev\", \"M.\", \"\"], [\"Hillebrands\", \"B.\", \"\"]], \"0704.0025\": [[\"Mishchenko\", \"A. S.\", \"\", \"1 and 2\"], [\"Nagaosa\", \"N.\", \"\", \"1 and 3\"]], \"0704.0026\": [[\"de Marrais\", \"Robert P. C.\", \"\"]], \"0704.0027\": [[\"Goerbig\", \"M. O.\", \"\"], [\"Fuchs\", \"J. -N.\", \"\"], [\"Kechedzhi\", \"K.\", \"\"], [\"Fal\\'ko\", \"Vladimir I.\", \"\"]], \"0704.0028\": [[\"Frenkel\", \"P\\\\u00e9ter E.\", \"\"]], \"0704.0029\": [[\"Shu\", \"Zhan\", \"\"], [\"Chen\", \"Xiao-Lin\", \"\"], [\"Deng\", \"Wei-Zhen\", \"\"]], \"0704.0030\": [[\"Hague\", \"J. P.\", \"\"], [\"d\\'Ambrumenil\", \"N.\", \"\"]], \"0704.0031\": [[\"Biryukov\", \"V. M.\", \"\", \"Serpukhov, IHEP\"]], \"0704.0032\": [[\"Esteban-Pretel\", \"A.\", \"\"], [\"Tom\\\\u00e0s\", \"R.\", \"\"], [\"Valle\", \"J. W. F.\", \"\"]], \"0704.0033\": [[\"Yurkin\", \"Maxim A.\", \"\"], [\"Maltsev\", \"Valeri P.\", \"\"], [\"Hoekstra\", \"Alfons G.\", \"\"]]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 0                        1  \\\n1970-01-01 00:11:44.000100          [Balázs, C., ]        [Berger, E. L., ]   \n1970-01-01 00:11:44.000200     [Streinu, Ileana, ]        [Theran, Louis, ]   \n1970-01-01 00:11:44.000300        [Pan, Hongjun, ]                     None   \n1970-01-01 00:11:44.000400       [Callan, David, ]                     None   \n1970-01-01 00:11:44.000500  [Abu-Shammala, Wael, ]  [Torchinsky, Alberto, ]   \n\n                                              2                 3     4     5  \\\n1970-01-01 00:11:44.000100  [Nadolsky, P. M., ]  [Yuan, C. -P., ]  None  None   \n1970-01-01 00:11:44.000200                 None              None  None  None   \n1970-01-01 00:11:44.000300                 None              None  None  None   \n1970-01-01 00:11:44.000400                 None              None  None  None   \n1970-01-01 00:11:44.000500                 None              None  None  None   \n\n                               6  \n1970-01-01 00:11:44.000100  None  \n1970-01-01 00:11:44.000200  None  \n1970-01-01 00:11:44.000300  None  \n1970-01-01 00:11:44.000400  None  \n1970-01-01 00:11:44.000500  None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1970-01-01 00:11:44.000100</th>\n      <td>[Balázs, C., ]</td>\n      <td>[Berger, E. L., ]</td>\n      <td>[Nadolsky, P. M., ]</td>\n      <td>[Yuan, C. -P., ]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1970-01-01 00:11:44.000200</th>\n      <td>[Streinu, Ileana, ]</td>\n      <td>[Theran, Louis, ]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1970-01-01 00:11:44.000300</th>\n      <td>[Pan, Hongjun, ]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1970-01-01 00:11:44.000400</th>\n      <td>[Callan, David, ]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1970-01-01 00:11:44.000500</th>\n      <td>[Abu-Shammala, Wael, ]</td>\n      <td>[Torchinsky, Alberto, ]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_small = pd.read_json(data, orient='index', dtype=False, convert_dates=False)\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./../data/loading/authors/authors-parsed.json\"\n",
    "with open(file_path) as json_file:\n",
    "     json_file = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file[\"0704.0001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "count = 0\n",
    "authors = []\n",
    "\n",
    "for key in json_file:\n",
    "    value = json_file[key]\n",
    "    #print(\"{} : {}\".format(key, value))\n",
    "    for author_list in value:\n",
    "        #author = {\"metadata_id\": key, \"author_string\": str(author_list), \"author_parsed\": f\"{author_list[1]} {author_list[0]} {author_list[2]}\"}\n",
    "        author = {\"metadata_id\": key, \"author\": f\"{author_list[1].replace(',', '')} {author_list[0].replace(',', '')} {author_list[2].replace(',', '')}\"}\n",
    "        #print(author)\n",
    "        authors.append(author)\n",
    "\n",
    "authors_df = pd.DataFrame(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(authors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = len(json_file.keys())\n",
    "values = len(json_file.values())\n",
    "print(keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'article_id': json_file.keys(), 'authors_list': json_file.values()}, columns=['article_id','authors_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_content = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(authors_df[authors_df['author'].str.contains(\",\")]) # We need to remove those commas\n",
    "#len(authors_df[authors_df['author_parsed'].str.contains(\",\")]) # We need to remove those commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./../data/loading/citations/internal-citations.json\"\n",
    "with open(file_path) as json_file:\n",
    "     json_file = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "citations = []\n",
    "\n",
    "for key in json_file:\n",
    "    value = json_file[key]\n",
    "    #print(\"{} : {}\".format(key, value))\n",
    "    for element in value:\n",
    "        citation = {\"metadata_id\": key, \"citation\": element}\n",
    "        citations.append(citation)\n",
    "    num += 1\n",
    "    if num > 10:\n",
    "        break\n",
    "\n",
    "citations_df = pd.DataFrame(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./../data/loading/metadata/arxiv-metadata-oai-snapshot-sample.json\"\n",
    "\n",
    "def get_metadata():\n",
    "    with open(data_file, 'r') as f:\n",
    "        for line in f:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "id: 0704.0001\nsubmitter: Pavel Nadolsky\nauthors: C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\ntitle: Calculation of prompt diphoton production cross sections at Tevatron and\n  LHC energies\ncomments: 37 pages, 15 figures; published version\njournal-ref: Phys.Rev.D76:013009,2007\ndoi: 10.1103/PhysRevD.76.013009\nabstract:   A fully differential calculation in perturbative quantum chromodynamics is\npresented for the production of massive photon pairs at hadron colliders. All\nnext-to-leading order perturbative contributions from quark-antiquark,\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\nall-orders resummation of initial-state gluon radiation valid at\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\nspecified in which the calculation is most reliable. Good agreement is\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\nmore detailed tests with CDF and DO data. Predictions are shown for\ndistributions of diphoton pairs produced at the energy of the Large Hadron\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\nboson are contrasted with those produced from QCD processes at the LHC, showing\nthat enhanced sensitivity to the signal can be obtained with judicious\nselection of events.\n\nreport-no: ANL-HEP-PR-07-12\ncategories: ['hep-ph']\nversions: ['v1', 'v2']\n"
    }
   ],
   "source": [
    "metadata = get_metadata()\n",
    "for paper in metadata:\n",
    "    for k, v in json.loads(paper).items():\n",
    "        print(f'{k}: {v}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit079b8e0c18c84c07a446e24cf94e2db0",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}