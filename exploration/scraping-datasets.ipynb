{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data scraped from arxiv.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) pip install bs4, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\"}\n",
    "page = 'https://arxiv.org/help/api/user-manual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_table_after_heading(soup, heading_text):\n",
    "    # Stolen from: https://stackoverflow.com/a/51936486\n",
    "    for header in soup.find_all('h3', text=re.compile(heading_text)):\n",
    "        nextNode = header\n",
    "        while True:\n",
    "            nextNode = nextNode.nextSibling\n",
    "            if nextNode is None:\n",
    "                break\n",
    "            if isinstance(nextNode, Tag):\n",
    "                if nextNode.name == \"h3\":\n",
    "                    break\n",
    "                #print(nextNode)\n",
    "                return nextNode\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "with requests.Session() as s:\n",
    "    # Get data\n",
    "    r = s.get(page, headers = headers)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    # Find table data we are looking for\n",
    "    table_node = find_table_after_heading(soup, '5.3. Subject Classifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(table_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over table data and convert dataframe\n",
    "data = []\n",
    "cols = ['tag','name']\n",
    "for tr in table_node.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    data.append([tds[0].text, tds[1].text])\n",
    "    #print(f\"tag: {tds[0].text}, name: {tds[1].text}\")\n",
    "df = pd.DataFrame.from_records(data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to disk\n",
    "df.to_csv('../data/subject-classifications.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Go to your Kaggle user account: https://www.kaggle.com/<user>/account\n",
    "# 2) Click [Create New API Token] and download kaggle.json file to your ~/.kaggle/ folder (create if needed)\n",
    "# 3) pip install kaggle, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://stackoverflow.com/questions/55934733/documentation-for-kaggle-api-within-python\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files of a dataset\n",
    "# Signature: dataset_download_files(dataset, path=None, force=False, quiet=True, unzip=False)\n",
    "# Url: https://www.kaggle.com/Cornell-University/arxiv\n",
    "api.dataset_download_files('Cornell-University/arxiv', path='../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit079b8e0c18c84c07a446e24cf94e2db0",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}